{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faml.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnpIj4rXwMGq+Ch8WM4buF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrefs/mapi-faml-proj/blob/main/code/faml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ldsbwbszEcU"
      },
      "source": [
        "# Load stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP9s2VRizdyq"
      },
      "source": [
        "\n",
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQLvl1ogzVBJ"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import urllib.request"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aln-D8hdzZ8U"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTh4iPaSqRP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97214029-755b-44d7-f778-45c597da3a98"
      },
      "source": [
        "# currently not being used\n",
        "def normalize(word_vec):\n",
        "    norm=np.linalg.norm(word_vec)\n",
        "    if norm == 0: \n",
        "       return word_vec\n",
        "    return word_vec/norm\n",
        "\n",
        "embs = {}\n",
        "url = 'https://raw.githubusercontent.com/andrefs/mapi-faml-proj/main/2_clean_datasets/embeddings.txt'\n",
        "response = urllib.request.urlopen(url)\n",
        "lines = [l.decode('utf-8') for l in response.readlines()]\n",
        "reader = csv.reader(lines, delimiter=' ')\n",
        "for line in reader:\n",
        "    term = line[0].replace('http://dbpedia.org/resource/' , '')\n",
        "    vector = [float(x) for x in line[1:]]\n",
        "    embs[term] = vector\n",
        "\n",
        "\n",
        "len(embs.keys())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFjrLpJoziz5"
      },
      "source": [
        "## Relatedness pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyynA0vIzm_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4738b325-7a26-4463-8edc-44e59930bc86"
      },
      "source": [
        "relness = {}\n",
        "url = 'https://raw.githubusercontent.com/andrefs/mapi-faml-proj/main/2_clean_datasets/relatedness.tsv'\n",
        "response = urllib.request.urlopen(url)\n",
        "lc = 0\n",
        "lines = [l.decode('utf-8') for l in response.readlines()]\n",
        "reader = csv.reader(lines, delimiter='\\t')\n",
        "for line in reader:\n",
        "    lc += 1\n",
        "    t1 = line[0].replace('http://dbpedia.org/resource/' , '')\n",
        "    t2 = line[1].replace('http://dbpedia.org/resource/' , '')\n",
        "    rel = float(line[2])\n",
        "    relness[t1] = relness.get(t1,{})\n",
        "    relness[t1][t2] = [float(line[2]), line[3]] # relatedness value and subset (train/test)\n",
        "\n",
        "lc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgQsIm1J3Oo5"
      },
      "source": [
        "# Merge data from both sources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z330Dhpk3N9u"
      },
      "source": [
        "X_m = []\n",
        "S_m = []\n",
        "Y_m = []\n",
        "for t1 in relness:\n",
        "    for t2 in relness[t1]:\n",
        "        Y_m.append(float(relness[t1][t2][0]))\n",
        "        S_m.append(relness[t1][t2][1])\n",
        "        X_m.append(embs[t1]+embs[t2])\n",
        "        #X_m.append(np.concatenate((embs[t1],embs[t2])))\n",
        "        \n",
        "\n",
        "# Use Numpy\n",
        "Y = np.array(Y_m)\n",
        "X = np.matrix(X_m).astype(float)\n",
        "S = np.array(S_m)\n",
        "\n",
        "# Use pandas\n",
        "#X_train = pd.DataFrame(X[np.in1d(S[:], 'Train')])\n",
        "#X_test  = pd.DataFrame(X[np.in1d(S[:], 'Test')])\n",
        "#Y_train = pd.DataFrame(Y[np.in1d(S[:], 'Train')])\n",
        "#Y_test  = pd.DataFrame(Y[np.in1d(S[:], 'Test')])\n",
        "\n",
        "\n",
        "X_train = X[np.in1d(S[:], 'Train')]\n",
        "X_test  = X[np.in1d(S[:], 'Test')]\n",
        "Y_train = Y[np.in1d(S[:], 'Train')]\n",
        "Y_test  = Y[np.in1d(S[:], 'Test')]\n",
        "\n",
        "# Insert target column into dataset\n",
        "#X_train['Target'] = Y_train\n",
        "# 200 columns = embeddings t1\n",
        "# 200 columns = embeddings t2\n",
        "#   1 column  = relatedness value (target)\n",
        "#X_train.describe()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DUsr3h5ogTH"
      },
      "source": [
        "## Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iP0UbOSogj7",
        "outputId": "5c588aab-36a1-41db-c37c-38c9dc65dae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def setup_model(topo, dropout_rate, input_size, output_size):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(topo[0], activation=\"relu\", input_dim = input_size))\n",
        "    if dropout_rate > 0: model.add(keras.layers.Dropout(dropout_rate))\n",
        "    for i in range(1,len(topo)):\n",
        "        model.add(keras.layers.Dense(topo[i], activation=\"relu\"))\n",
        "        if dropout_rate > 0: model.add(keras.layers.Dropout(dropout_rate))\n",
        "    model.add(keras.layers.Dense(output_size))\n",
        "    model.add(keras.layers.Activation('softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_dnn(model, alg, lr, Xtrain, Ytrain, epochs = 5, batch_size = 64):\n",
        "    if alg == \"adam\":\n",
        "        optimizer = keras.optimizers.Adam(lr = lr)\n",
        "    elif alg == \"rmsprop\":\n",
        "        optimizer = keras.optimizers.RMSprop(lr = lr)\n",
        "    elif alg == \"sgd_momentum\":\n",
        "        optimizer = keras.optimizers.SGD(lr = lr, momentum = 0.9)\n",
        "    else: optimizer = keras.optimizers.SGD(lr = lr)\n",
        "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "    model.fit(Xtrain, Ytrain, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
        "    return model\n",
        "\n",
        "def dnn_optimization(opt_params, Xtrain, Ytrain, Xval, Yval, iterations = 10, verbose = True):\n",
        "    from random import choice\n",
        "    if verbose: print(\"Topology\\tDropout\\tAlgorithm\\tLRate\\tValLoss\\tValAcc\\n\")\n",
        "    best_acc = None\n",
        "\n",
        "    Ytrain = Ytrain.reshape(-1,1)\n",
        "    input_size = Xtrain.shape[1]\n",
        "    output_size = Ytrain.shape[1]\n",
        "\n",
        "    if \"topology\" in opt_params: topologies = opt_params[\"topology\"]\n",
        "    else: topologies = [[100]]\n",
        "    if \"algorithm\" in opt_params: algs = opt_params[\"algorithm\"]\n",
        "    else: algs = [\"adam\"]\n",
        "    if \"lr\" in opt_params: lrs = opt_params[\"lr\"]\n",
        "    else: lrs = [0.001]\n",
        "    if \"dropout\" in opt_params: dropouts = opt_params[\"dropout\"]\n",
        "    else: dropouts= [0.0]\n",
        "    for it in range(iterations):\n",
        "        topo = choice(topologies)\n",
        "        dropout_rate = choice(dropouts)\n",
        "        dnn = setup_model (topo, dropout_rate, input_size, output_size)\n",
        "        alg = choice(algs)\n",
        "        lr = choice(lrs)\n",
        "        dnn = train_dnn(dnn, alg, lr, Xtrain, Ytrain)\n",
        "        val_loss, val_acc = dnn.evaluate(Xval, Yval, verbose = 0)\n",
        "\n",
        "        if verbose:\n",
        "            print(topo, \"\\t\", dropout_rate, \"\\t\", alg, \"\\t\", lr, \"\\t\", val_loss, \"\\t\", val_acc)\n",
        "        \n",
        "        if best_acc is None or val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_config = (topo, dropout_rate, alg, lr)\n",
        "    return best_config, best_acc\n",
        "                         \n",
        "                         \n",
        "\n",
        "opt_pars = {\"topology\":[[100,50], [400,600,600,200,100]], \"algorithm\": [ \"adam\", \"rmsprop\", \"sgd_momentum\"], \"lr\": [0.01, 0.001], \"dropout\": [0, 0.2, 0.5]}\n",
        "best_config, best_acc = dnn_optimization(opt_pars, X_train, Y_train, X_test, Y_test)\n",
        "print(best_config)\n",
        "print(best_acc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topology\tDropout\tAlgorithm\tLRate\tValLoss\tValAcc\n",
            "\n",
            "[100, 50] \t 0 \t adam \t 0.001 \t 0.0 \t 0.03424213081598282\n",
            "[400, 600, 600, 200, 100] \t 0 \t sgd_momentum \t 0.01 \t nan \t 0.4961051642894745\n",
            "[100, 50] \t 0.2 \t rmsprop \t 0.001 \t 0.0 \t 0.03424213081598282\n",
            "[100, 50] \t 0.5 \t rmsprop \t 0.001 \t 0.0 \t 0.03424213081598282\n",
            "[100, 50] \t 0 \t adam \t 0.001 \t 0.0 \t 0.03424213081598282\n",
            "[400, 600, 600, 200, 100] \t 0.5 \t rmsprop \t 0.001 \t 0.0 \t 0.03424213081598282\n",
            "[100, 50] \t 0 \t rmsprop \t 0.001 \t 0.0 \t 0.03424213081598282\n",
            "[100, 50] \t 0.2 \t adam \t 0.001 \t 0.0 \t 0.03424213081598282\n",
            "[400, 600, 600, 200, 100] \t 0.2 \t adam \t 0.001 \t 0.0 \t 0.03424213081598282\n",
            "[100, 50] \t 0.2 \t sgd_momentum \t 0.01 \t nan \t 0.4961051642894745\n",
            "([400, 600, 600, 200, 100], 0, 'sgd_momentum', 0.01)\n",
            "0.4961051642894745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeoxX8sBqHt_",
        "outputId": "281ad9e0-0710-4e0c-9248-04615c0b123a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[ 7.4500e-03,  4.5770e-03, -1.9916e-02, ...,  7.8440e-03,\n",
              "          4.9000e-05,  4.7807e-02],\n",
              "        [ 7.4500e-03,  4.5770e-03, -1.9916e-02, ...,  3.1100e-03,\n",
              "          2.1360e-03, -3.5700e-03],\n",
              "        [-1.5811e-02, -1.4104e-02,  6.1710e-03, ...,  3.2520e-03,\n",
              "          3.4900e-03, -1.8630e-02],\n",
              "        ...,\n",
              "        [ 2.3294e-02,  3.8200e-03, -8.4220e-03, ..., -7.7490e-03,\n",
              "         -7.0800e-04, -2.1870e-02],\n",
              "        [ 1.3664e-02,  1.9900e-04, -2.5430e-02, ..., -1.3498e-02,\n",
              "          5.4900e-04, -1.0503e-02],\n",
              "        [ 3.0580e-03, -7.9860e-03, -3.4400e-02, ..., -6.2000e-05,\n",
              "          8.0900e-04, -4.6170e-03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}